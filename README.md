# LLM-PlaygroundSTATS
A Gradio Playground with LLMs (llama.cpp or Transformers) with CPU/RAM usage statistics

## General Information
This repo hosts python file with GRADIO UI
the tested LLMs are
- Flan-T5-base - pytorch/Transformers
- Dolphi2.6-Phi2 GGUF - llama.cpp
- Phi1.5 GGUF - llama.cpp

## UI enhanchements
- like/dislike buttons to evaluate the output
- A comment section to explain the results of the tuning paraemters and issues on the prompt
- Temperature, Repetition Penalty and Max generation lenght sliders
- CLEAR field Button
- CPU statistic plot
- RAM statistic plot

---

screeshots examples
<img src="https://github.com/fabiomatricardi/LLM-PlaygroundSTATS/raw/main/Dolphin2.6-Phi2_PlayGround.png" width=900>


#### Supporting links
- ICON from https://github.com/Lightning-AI/lit-llama
- PLOTLY tutorial https://plotly.com/python/text-and-annotations/
- COLOR codes from https://html-color.codes/gold/chart
