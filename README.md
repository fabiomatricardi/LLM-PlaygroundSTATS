# LLM-PlaygroundSTATS
A Gradio Playground with LLMs (llama.cpp or Transformers) with CPU/RAM usage statistics

## General Information
This repo hosts python file with GRADIO UI
the tested LLMs are
- Flan-T5-base - pytorch/Transformers
- Dolphi2.6-Phi2 GGUF - llama.cpp
- Phi1.5 GGUF - llama.cpp

## UI enhanchements
- like/dislike buttons to evaluate the output
- A comment section to explain the results of the tuning paraemters and issues on the prompt
- Temperature, Repetition Penalty and Max generation lenght sliders
- CLEAR field Button
- CPU statistic plot
- RAM statistic plot

---

screeshots examples
<img src="https://github.com/fabiomatricardi/LLM-PlaygroundSTATS/raw/main/Dolphin2.6-Phi2_PlayGround.png" width=900>
